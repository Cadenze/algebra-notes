\chapter{Vector Spaces}\label{sec:linear-algebra}\label{sec:vsp}

\begin{remark}
    We shall resume the following convention as in Section~\ref{sec:matrix-rings}:
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item \(a\) a lowercase symbol denotes a generic element in a set;
        \item \(\vec{a}\) an underlined symbol denotes a vector; and
        \item \(\vb{A}\) a bold symbol (usually uppercase)
            denotes a matrix or tensorial quantity.
    \end{enumerate}
\end{remark}
\begin{remark}
    All homomorphisms in this chapter are assumed to be \(F\)-vector space homomorphisms;
    that is, \(\Hom(U,V) = \Hom_F(U,V)\) for \(U,V\) being \(F\)-vector spaces.
\end{remark}

\section{Basic Definitions}

\begin{definition}
    A left module over a ring \(R\) is a quadruple \((M,+,\cdot,\vec{0})\)
    where \(\vec{0} \in M\) is a set equipped with addition \(+\)
    with an identity \(\vec{0}\)
    and scalar multiplication,
    with the following four properties:
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item \((M,+,\vec{0})\) forms an abelian group;
        \item scalar multiplication
            \(\vfunc{\cdot}{R \times M}{M}{(\alpha,\vec{m})}{\alpha\vec{m}}\),
            and in particular \(1\vec{m} = \vec{m}\);
        \item \(\forall\{\alpha,\beta\} \in R,\, \forall\{\vec{m},\vec{n}\} \subset M\),
            the distributive laws \((\alpha+\beta)(\vec{m}+\vec{n})
            = \alpha\vec{m}+\alpha\vec{n}+\beta\vec{m}+\beta\vec{n}\) hold; and
        \item associativity
            \(\forall\{\alpha,\beta\} \subset R,\,\forall\vec{m} \in M\),
            \((\alpha\beta)\vec{m} = \alpha(\beta\vec{m})\).
    \end{enumerate}
\end{definition}
\begin{definition}
    A vector space over a field \(F\) is similarly defined with \(R = F\).
    It is a quadruple \((V,+,\cdot,\vec{0})\)
    where \(\vec{0} \in V\) is a set equipped with addition \(+\)
    with an identity \(\vec{0}\)
    and scalar multiplication,
    with the following four properties:
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item \((V,+,\vec{0})\) forms an abelian group;
        \item scalar multiplication
            \(\vfunc{\cdot}{F \times V}{M}{(\alpha,\vec{v})}{\alpha\vec{v}}\),
            and in particular \(1\vec{v} = \vec{v}\);
        \item \(\forall\{\alpha,\beta\} \in R,\, \forall\{\vec{u},\vec{v}\} \subset M\),
            the distributive laws \((\alpha+\beta)(\vec{u}+\vec{v})
            = \alpha\vec{u}+\alpha\vec{v}+\beta\vec{u}+\beta\vec{v}\) hold; and
        \item associativity
            \(\forall\{\alpha,\beta\} \subset R,\,\forall\vec{v} \in M\),
            \((\alpha\beta)\vec{v} = \alpha(\beta\vec{v})\).
    \end{enumerate}
\end{definition}
\begin{proposition}
    Suppose \(F\) is a field,
    and \(F^X = \{\func{f}{X}{F}\}\) the set of all functions from \(X\) to \(F\).
    When equipped with pointwise addition and multiplication,
    this forms a vector space over \(F\).
\end{proposition}
\begin{proof}
    Since addition and multiplication is pointwise,
    all proofs essentially start with `for all \(x \in X\) \(f(x) \in F\)',
    so distributive laws and associativity laws are inherited from \(F\).
\end{proof}
\begin{corollary}
    \(F^n\) forms a vector space.
\end{corollary}
\begin{proof}
    Simply consider \(X = \{0,1,\hdots,n-1\}\) an \(n\)-element set.
\end{proof}

\begin{definition}
    Suppose \((V,+,\cdot,0,1)\) is a vector space.
    Then \(W\) is a subspace if \(W \subseteq V\)
    and its additive and multiplicative groups form subgroups.
\end{definition}

\begin{definition}
    For any sequence of vectors \({\{\vec{v}_i\}}_{i=1}^r\),
    finite summation is recursively defined as
    \begin{equation*}
        \sum_{i=1}^0 \vec{v}_i = \vec{0} \qquad
        \sum_{i=1}^{r+1} \vec{v}_i = \vec{v}_{r+i} + \sum_{i=1}^r \vec{v}_i \qquad
        \sum_{i=m}^n \vec{v}_i = \sum_{i=1}^n \vec{v}_i - \sum_{i=1}^{m-1} \vec{v}_i
    \end{equation*}
\end{definition}

\begin{definition}
    Suppose \(V\) is a vector space over \(F\)
    (not necessarily finite-dimensional),
    and \(S \subseteq V\) some subset.
    Then
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item a vector \(\vec{v} \in V\) (linearly) depends on \(S\)
            if there are finite sets \(\exists {\{\vec{w}_i\}}_{i=1}^r \subset V\),
            \(\exists {\{a_i\}}_{i=1}^r \subset F\),
            such that it can written as a linear combination
            \(\sum_{i=1}^r a_i \vec{w}_i\);
        \item the span (or the \(F\)-span), denoted \(\Span(S)\) or \(\Span_F(S)\),
            is the set of all vectors in \(V\) that depend on \(S\);
        \item \(S\) is (linearly) dependent if \(\exists \vec{v} \in S\)
            such that \(\vec{v}\) depends on \(S \setminus \{\vec{v}\}\),
            and it is (linearly) independent otherwise; and
        \item \(S\) forms a basis of \(V\)
            if \(S\) is (linearly) independent and \(V = \Span(S)\).
    \end{enumerate}
\end{definition}
\begin{lemma}\label{lem:intersection-subspace}
    Suppose \(V\) a vector space, and \(W_i \subseteq V\) subspaces.
    Then \(\bigcap_i W_i\) is also a subspace of \(V\).
\end{lemma}
\begin{proof}
    Apply Lemma~\ref{lem:intersection-subgroup} twice
    exactly like Lemma~\ref{lem:intersection-subring}.
\end{proof}
\begin{proposition}\label{prop:subset-generated-subspace}
    \(\Span(S) = \bigcap_{S \subset W \subset V} W\)
    where \(W\) is a subspace of \(V\).
\end{proposition}
\begin{proof}
    Apply Proposition~\ref{prop:subset-generated-subgroup} twice
    exactly like Proposition~\ref{prop:subset-generated-subring}.
\end{proof}

\begin{lemma}
    \(S\) is dependent if and only if 
    there are distinct \({\{\vec{v}_i\}}_{i=1}^r \subset S\)
    and coefficients \({\{a_i\}}_{i=1}^r \subset F\) that are not all 0
    such that \(\sum_{i=1}^r a_i \vec{v}_i = \vec{0}\).
\end{lemma}
\begin{proof}
    \begin{equation*}
        \vec{v} = \sum_{i=1}^r a_i \vec{v}_i
        \iff \vec{0} = -\vec{v} + \sum_{i=1}^r a_i \vec{v}_i
    \end{equation*}
\end{proof}

\begin{definition}
    Suppose \(U,V\) are vector spaces, and \(\func{f}{U}{V}\) a function.
    \(f\) is linear if \(f(a\vec{u}+\vec{v}) = af(\vec{u}) + f(\vec{v})\),
    i.e.\ it preserves both operations.
\end{definition}
\begin{definition}
    Vector space homomorphisms are linear maps.
\end{definition}
\begin{proposition}
    \(\End(V) = \Hom(V,V)\) endomorphisms of a vector space
    has both a ring structure and a vector space structure.
\end{proposition}
\begin{proof}
    Let \(\func{0}{V}{V}\) map every vector to \(\vec{0}\),
    and \(\func{1}{V}{V}\) be the identity map.
    Clearly if \(\func{f,g}{V}{V}\),
    \(af(\vec{x}) = f(a\vec{x})\) by the fact that it is a linear map,
    and addition is defined the obvious way.
    If we define ring multiplication as function composition,
    then by linearity we have distributivity.
\end{proof}


\section{General Constructions}

\subsection*{Direct Sum}

\begin{definition}[Universal Property of Direct Sum]
    Suppose \({\{V_i\}}_{i \in I}\) is a family of vector spaces.
    The direct sum of vector spaces \(\bigoplus_{i \in I} V_i\)
    is the categorical coproduct of vector spaces, that is,
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item there exist embeddings \(\func{\iota_i}{V_i}{\bigoplus_{i \in I} V_i}\); and
        \item for any vector space \(X\),
            if \(\func{\phi_i}{V_i}{X}\) are homomorphisms,
            then there exists a unique \(\func{\bar{\phi}}{\bigoplus_{i \in I} V_i}{X}\)
            such that \(\phi_i = \bar{\phi}\circ\iota_i\).
    \end{enumerate}

    This can be represented by the logical statement
    \begin{equation*}
        \forall X\in\mathbf{Vect},\;
        \forall i \in I,\; \forall \phi_i\in\Hom(V_i,X),\;
        \exists! \phi\in\Hom\qty(\bigoplus_{i \in I} V_i,X),\;
        \phi_i = \bar{\phi}\circ\iota_i
    \end{equation*}
    and the following commutative diagram:
    \begin{center}
        \begin{tikzcd}
            V_i \arrow{r}{\phi_i} \arrow{d}{\iota_i} & X \\
            \bigoplus_{i \in I} V_i \arrow[dashrightarrow]{ru}[swap]{\exists! \bar{\phi}}
        \end{tikzcd}
    \end{center}
\end{definition}

\begin{definition}
    Suppose \(U,V\) are \(F\)-spaces.
    The external direct sum \(U \oplus V\)
    is a vector space \(U \times V\)
    equipped with coordinate-wise operations.
\end{definition}
\begin{lemma}
    \(U \oplus V\) indeed forms a vector space.
\end{lemma}
\begin{proof}
    The additive groups is a direct sum of (abelian) groups,
    which is (abelian) group.
    Check scalar multiplication by
    \begin{equation*}
        (ab)(\vec{u},\vec{v}) = ((ab)\vec{u},(ab)\vec{v})
        = (a(b\vec{u}),a(b\vec{v})) = a(b\vec{u},b\vec{v})
        = a(b(\vec{u},\vec{v}))
    \end{equation*}
\end{proof}
\begin{lemma}
    \(\dim_F(U \oplus V) = \dim_F U + \dim_F V\).
\end{lemma}
\begin{proof}
    Suppose \(B_U \subset U\) and \(B_V \subset V\) be bases.
    Let \(B = {\{(\vec{u},\vec{0})\}}_{\vec{u} \in B_U} \sqcup
    {\{(\vec{0},\vec{v})\}}_{\vec{v} \in B_V}\) be a disjoint union.
    We wish to prove that this forms a basis.
    \begin{equation*}
        \sum_i a_i(\vec{u}_i,\vec{0}) + \sum_j b_j(\vec{0},\vec{v}_j)
        = (\vec{0},\vec{0})
    \end{equation*}
    invokes linear independence by each of \(U\) and \(V\),
    so all \(a_i\) and \(b_j\) are zero.
    Then clearly \(B\) spans \((\vec{u},\vec{v})\)
    simply by span of \(B_U\) and \(B_V\).
\end{proof}

\begin{theorem}[Existence of Direct Sum]
    The direct sum of vector spaces \(V_i\)
    is a sum of elements \(x_i \in V_i\), with finite support.
    Addition and scalar multiplication respect usual summation rules.
\end{theorem}
\begin{proof}
    We prove that our vector space of finite sums does fulfill the universal property.
    We shall first prove uniqueness of \(\bar{\phi}\), assuming existence.
    Suppose, by way of contradiction,
    that \(\bar{\phi} \neq \bar{\phi}'\) both fulfill this diagram.
    Then there exists some finite sum \(\sum_{i \in I} \iota_i(x_i)\) such that
    \begin{equation*}
        \sum_{i \in I} \phi_i(x_i)
        = \sum_{i \in I} (\bar{\phi}\circ\iota_i)(x_i)
        = \bar{\phi}\pqty{\sum_{i \in I} \iota_ix(x_i)}
        \neq \bar{\phi}'\pqty{\sum_{i \in I} \iota_i(x_i)}
        = \sum_{i \in I} (\bar{\phi}'\circ\iota_i)(x_i)
        = \sum_{i \in I} \phi_i(x_i)
    \end{equation*}
    which is a contradiction.

    We now prove existence.
    We wish to show that we can define \(\bar{\phi}\) as
    \(\sum \iota_i(x_i) \mapsto \sum \phi_i(x_i)\).
    We first check linearity,
    and that we pad our sums below with zeroes,
    so that they are both sums with same number of terms.
    \begin{align*}
        \bar{\phi}\pqty{a\sum \iota_i(x_i) + \sum \iota_i(y_i)}
        &= \bar{\phi}\pqty{\sum (a\iota_i(x_i)+\iota_i(y_i))}
        = \pqty{\sum (\bar{\phi}\circ\iota_i)(ax_i + y_i)}
        = \sum \phi_i(ax_i + y_i) \\
        &= a\sum \phi_i(x_i) + \sum \phi_i(y_i)
        = a\bar{\phi}\pqty{\sum \iota_i(x_i)} + \bar{\phi}\pqty{\sum \iota_i(y_i)}
    \end{align*}
    The fact that \(\bar{\phi}\circ\iota_i = \phi_i\) is by construction.
\end{proof}
\begin{remark}
    In general, when proving a universal property,
    we start by proving uniqueness assuming existence,
    and then proving existence afterwards.
    This is because the details of the proof of existence
    is often revealed while proving uniqueness.
\end{remark}
\begin{theorem}[Uniqueness of Direct Sum]
    The direct sum of vector spaces is unique up to isomorphism.
\end{theorem}
\begin{proof}
    Suppose, by way of contradiction,
    that there exists some \(W\) that also fits the universal property.
    \begin{center}
        \begin{tikzcd}
            V_i \arrow{r}{\iota_i'} \arrow{d}{\iota_i} &
            W \arrow[rightharpoondown, shift right=0.25ex]{ld}%
                [xshift=.5ex, yshift=-.5ex, swap]{\bar{\phi}'} \\
            \bigoplus_{i \in I} V_i \arrow[rightharpoondown, shift right=0.25ex]{ru}%
                [xshift=-.5ex, yshift=.5ex, swap]{\bar{\phi}}
            % F' \arrow[rightharpoondown, shift right=0.25ex]{ld}%
            %     [xshift=.5ex, yshift=-.5ex, swap]{\bar{\phi}'} \\
            % F \arrow[rightharpoondown, shift right=0.25ex]{ru}%
            %     [xshift=-.5ex, yshift=.5ex, swap]{\bar{\phi}}
        \end{tikzcd}
    \end{center}
    % It is obvious from the universal property that
    % the unique inclusions do not get affected by order or bracketing.
    We can see from the diagram that \((\bar{\phi}'\circ\bar{\phi})\circ\iota_i = \iota_i\),
    so by the uniqueness of \(\bar{\phi}\) and \(\bar{\phi}'\) in this diagram,
    \(\bar{\phi}'\circ\bar{\phi} = \id\).
    The same argument can be used to conclude that \(\bar{\phi}\circ\bar{\phi}' = \id\).
    Hence \(\bar{\phi}^{-1} = \bar{\phi}'\),
    and we have isomorphism.
\end{proof}

\begin{proposition}\label{prop:vsp-sum-iso}
    We have the following canonical isomorphisms:
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \((U \oplus V) \oplus W \cong U \oplus V \oplus W \cong U \oplus (V \oplus W)\); and
        \item \(U \oplus V \cong V \oplus U\).
    \end{enumerate}
\end{proposition}
\begin{proof}
    Suppose \(\vec{u} \in U\), \(\vec{v} \in V\), and \(\vec{w} \in W\).
    Then we have the following maps:
    \((\vec{u}+\vec{v})+\vec{w} \mapsto \vec{u}+\vec{v}+\vec{w} \mapsto \vec{u}+(\vec{v}+\vec{w})\).
    Both of these maps are isomorphic,
    because the bases are concatenated from the bases of \(U,V,W\).
    % for \(\vec{u}_i,\vec{v}_j,\vec{w}_k\) basis vectors.

    A similar argument can be made for part (b).
    The bases are both dependent on the choice of \(\vec{u}_i,\vec{v}_j\),
    since the bases this time is concatenated from a different order only.
\end{proof}
% \begin{proposition}
%     \(\dim(\bigoplus_{i=1}^n V_i) = \sum_{i=1}^n \dim(V_i)\).
% \end{proposition}
% \begin{proof}
    
% \end{proof}


\subsection*{Direct Product}

\begin{definition}[Universal Property of Direct Product]
    Suppose \({\{V_i\}}_{i \in I}\) is a family of vector spaces.
    The direct product of vector spaces \(\prod_{i \in I} V_i\)
    is the categorical product of vector spaces, that is,
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item there exists projections \(\func{\pi_i}{\prod_{i \in I} V_i}{V_i}\); and
        \item for any vector space \(X\), if \(\func{\phi_i}{X}{V_i}\) are homomorphisms,
            then there exists a unique \(\func{\bar{\phi}}{X}{\prod_{i \in I} V_i}\)
            such that \(\phi_i = \pi_i\circ\bar{\phi}\).
    \end{enumerate}

    This can be represented by the logical statement
    \begin{equation*}
        \forall X \in \mathbf{Vect},\;
        \forall i \in I,\;
        \forall \phi_i \in \Hom(X,V_i),\;
        \exists! \phi \in \Hom\qty(X,\prod_{i \in I} V_i),\;
        \phi_i = \pi_i \circ \bar{\phi}
    \end{equation*}
    and the following commutative diagram:
    \begin{center}
        \begin{tikzcd}
            V_i & X \arrow{l}[swap]{\phi_i}%
                \arrow[dashrightarrow]{ld}{\exists! \bar{\phi}} \\
            \prod_{i \in I} V_i \arrow{u}[swap]{\pi_i}
                % \arrow[dashrightarrow]{ru}[swap]{\exists! \bar{\phi}}
        \end{tikzcd}
    \end{center}
\end{definition}

\begin{theorem}[Existence of Direct Product]
    The direct product of vector spaces is a tuple \({(x_i)}_{i \in I}\) indexed over \(I\),
    with each element \(x_i \in V_i\).
\end{theorem}
\begin{proof}
    We prove that our vector space of tuples does fulfill the universal property.
    We shall first prove uniqueness of \(\bar{\phi}\), assuming existence.
    Suppose, by way of contradiction,
    that \(\bar{\phi} \neq \bar{\phi}'\) both fulfill this diagram.
    Then there exists some element \(x \in X\) such that
    \(\bar{\phi}(x) \neq \bar{\phi}'(x)\).
    But we have, for all \(i \in I\)
    \begin{equation*}
        (\pi_i\circ\bar{\phi})(x) = \phi_i(x) = (\pi_i\circ\bar{\phi}')(x)
    \end{equation*}
    so we have two different elements projecting to the same elements in \(V_i\).
    That is a contradiction, since if all projections agree,
    then the tuples must agree at all positions.

    We now prove existence.
    We wish to show that we can define \(\bar{\phi}\) as
    \(x \mapsto {(\phi_i(x))}_{i \in I}\).
    We first check linearity.
    \begin{equation*}
        \bar{\phi}(ax + y) = {(\phi_i(ax+y))}_{i \in I}
        = {(a\phi_i(x) + \phi_i(y))}_{i \in I}
        = a{(\phi_i(x))}_{i \in I} + {(\phi_i(y))}_{i \in I}
        = a\bar{\phi}(x) + \bar{\phi}(y)
    \end{equation*}
    The fact that \(\pi_i\circ\bar{\phi} = \phi_i\) is by construction.
\end{proof}
\begin{theorem}[Uniqueness of Direct Product]
    The direct product of vector spaces is unique up to isomorphism.
\end{theorem}
\begin{proof}
    Suppose, by way of contradiction, that there exists another vector space \(W\)
    that fits this universal property.
    \begin{center}
        \begin{tikzcd}
            V_i & %
                % \arrow[dashrightarrow]{ld}{\exists! \bar{\phi}} \\
            % \prod_{i \in I} V_i \
            W \arrow[rightharpoondown, shift right=0.25ex]{ld}%
                [xshift=.5ex, yshift=-.5ex, swap]{\bar{\phi}'} \arrow{l}[swap]{\pi_i'} \\
            \prod_{i \in I} V_i \arrow[rightharpoondown, shift right=0.25ex]{ru}%
                [xshift=-.5ex, yshift=.5ex, swap]{\bar{\phi}} \arrow{u}[swap]{\pi_i}
        \end{tikzcd}
    \end{center}
    Again, from the universal property,
    \(\pi_i\circ(\bar{\phi}'\circ\bar{\phi}) = \pi_i\),
    and by uniqueness, \(\bar{\phi}'\circ\bar{\phi} = \id\).
    A similar argument gives \(\bar{\phi}\circ\bar{\phi}' = \id\).
    Hence we have isomorphism.
\end{proof}

\begin{theorem}\label{thm:vsp-sum-prod-iso}
    Suppose \({\{V_i\}}_{i=1}^n\) is a finite family of vector spaces.
    Then the direct sum and direct product of finitely many vector spaces are isomorphic.
    \begin{equation*}
        \bigoplus_{i=1}^n V_i \cong \prod_{i=1}^n V_i
    \end{equation*}
\end{theorem}
\begin{proof}
    The following projections and inclusions clearly give a surjection
    from the direct product to the direct sum.
    \begin{center}
        \begin{tikzcd}
            \prod_{i=1}^n V_i \arrow{r}{\pi_i} &
            V_i \arrow{r}{\iota_i} &
            \bigoplus_{i=1}^n V_i
        \end{tikzcd}
    \end{center}
    It suffices to prove that this is also injective.
    But the \hyperref[thm:pigeonhole]{pigeonhole principle}
    gives us that a surjection of finitely many vector spaces
    must also be an injection.
\end{proof}
\begin{remark}
    In infinite indices,
    the direct sum is a smaller space than the direct product.
    Choosing canonical coordinates,
    the direct sum can only have finite support with respect to its basis,
    but the direct product can have infinite support.
\end{remark}

\begin{proposition}
    We have the following canonical isomorphisms:
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \((U \times V) \times W \cong U \times V \times W \cong U \times (V \times W)\); and
        \item \(U \times V \cong V \times U\).
    \end{enumerate}
\end{proposition}
\begin{proof}
    Since Theorem~\ref{thm:vsp-sum-prod-iso} tells us we have an isomorphism
    between the finite direct sum and direct product,
    Proposition~\ref{prop:vsp-sum-iso} suffices.
\end{proof}


\subsection*{Quotient}

\begin{proposition}[Universal Property of Quotients]
    Suppose \(V\) is a vector space, and \(U \subseteq V\) is a subspace,
    and \(\func{\pi}{V}{U}\) is the quotient map as groups.
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \(\pi\) is a linear map, and there exists a unique vector space structure on \(V/U\);
        \item For any vector space \(Z\), if we have \(f \in \Hom(V,Z)\) and \(\ker(f) \supseteq U\),
            then there exists a unique linear map \(\bar{f} \in \Hom(V/U,Z)\)
            such that \(\bar{f} \circ g = f\).
    \end{enumerate}

    This can be represented by the following commutative diagram:
    \begin{center}
        \begin{tikzcd}
            V \arrow{d}{\pi} \arrow{r}{f} & Z \\
            V/U \arrow[dashrightarrow]{ru}[swap]{\exists! \bar{f}}
        \end{tikzcd}
    \end{center}
\end{proposition}
\begin{proof}
    Suppose \(\vec{x} \in V/U\).
    If \(\vec{x} = \vec{v} + U + \vec{v}' + U\),
    then we can see that \(a\vec{v}-a\vec{v}' = a(\vec{v}-\vec{v}') \in U\),
    which allows us to conclude that \(\pi(a\vec{v}) = \pi(a\vec{v}') = a\pi(\vec{v})\)
    is well-defined.
    The additive axioms are clearly satisfied,
    so it suffices to check distributivity.
    \begin{equation*}
        \pi(a\vec{v}+a\vec{w}) = a\pi(\vec{v}) + a\pi(\vec{w})
        = a\pi(\vec{v} +\vec{w})
    \end{equation*}
\end{proof}

\begin{theorem}[First Isomorphism Theorem for Vector Spaces]\label{thm:iso-1-vsp}
    Suppose \(\func{\phi}{V}{W}\) is a vector space homomorphism,
    and \(U = \ker(\phi)\).
    We have:
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \(U \subseteq V\), the kernel is a subspace;
        \item \(\phi(V) \subseteq W\), the image is a subspace; and
        \item \(\phi(V) \cong V/W\), the image is uniquely isomorphic to the quotient subspace.
    \end{enumerate}
\end{theorem}
\begin{theorem}[Third and Fourth Isomorphism Theorems for Vector Spaces]\label{thm:iso-3-vsp}\label{thm:iso-4-vsp}
    Suppose \(V\) is a vector space, \(U \subseteq V\) some subspace,
    and \(\func{\pi}{V}{V/U}\) is the quotient homomorphism.
    Then \(\pi\) is a bijection between the subspaces of \(V/U\)
    and the subspaces of \(V\) containing \(U\).
    In particular, if \(W\) is one such intermediate subspace,
    then \((V/U)/(W/U) \cong V/W\).
\end{theorem}
\begin{remark}
    Observe that vector spaces are modules over fields,
    so these isomorphism theorems are direct consequences of
    \hyperref[thm:iso-1-module]{isomorphism theorems on modules},
    which we will give a treatment in Chapter~\ref{sec:modules}.
    However, as the reader might be observed
    from the proofs of the isomorphism theorems
    for \hyperref[thm:iso-1-group]{groups} and \hyperref[thm:iso-1-ring]{rings},
    the direct proof of these theorems follow the exact same line of reasoning.
\end{remark}
% EDIT WHEN UNIVERSAL ALGEBRA WRITTEN


\section{Duality}

\begin{definition}
    Suppose \(V\) is an \(F\)-vector space.
    The dual vector space is \(V' = \Hom_F(V,F)\)
    the set of all homomorphisms into the base field.
    In some other fields of math the dual is sometimes denoted \(V^\ast\).
\end{definition}
\begin{lemma}
    Suppose \(W\) and \(V\) are \(F\)-vector spaces. Then
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \(W^V\) is a vector space under coordinate-wise operations; and
        \item \(\Hom_F(W,V) \subseteq W^V\) is a subspace.
    \end{enumerate}
\end{lemma}
\begin{proof}
    \(W^V = \prod_{\vec{v} \in V} W\),
    which by the universal property of the direct product is a vector space.

    The homomorphisms are clearly a subset,
    so it suffices to prove that it is a vector space.
    The zero morphism is trivially linear,
    so we show that if \(f,g\) are linear,
    \begin{align*}
        (af+g)(b\vec{u}+\vec{v}) &= af(b\vec{u}+\vec{v}) + g(b\vec{u}+\vec{v})
        = baf(\vec{u}) + af(\vec{v}) + bg(\vec{u}) + g(\vec{v}) \\
        &= b(af(\vec{u}) + g(\vec{u})) + af(\vec{v}) + g(\vec{v})
        = b(af+g)(\vec{u}) + (af+g)(\vec{v})
    \end{align*}
\end{proof}
\begin{proposition}
    \({(V/U)}' = \{\phi \in V' : \phi\vert_U = \vec{0}\}\).
\end{proposition}
\begin{proof}
    Suppose \(\phi \in {(V/U)}'\).
    Then we can extend this to \(\phi\circ\pi\),
    which since it factors through \(V/U\),
    the kernel contains \(U\),
    so \({(V/U)}' \subseteq \{\phi \in V' : \phi\vert_U = \vec{0}\}\).
    On the other hand, if \(\phi\vert_U = \vec{0}\),
    by the universal property of quotients,
    we can find a corresponding morphism \(V/U \to F\),
    i.e.\ in \({(V/U)}'\).
\end{proof}

\begin{definition}
    Suppose \(B \subset V\) is a basis.
    The dual basis \(B' \subset V'\) is a set where for each \(\vec{u} \in B\),
    there is a corresponding \(\phi_{\vec{u}} \in B'\)
    such that \(\phi_{\vec{u}}(\vec{v}) = \delta_{\vec{u},\vec{v}}\)
    for all \(\vec{v} \in B\),
    where \(\delta\) is the Kronecker delta.
\end{definition}
\begin{lemma}
    Suppose \(B = {\{\vec{v}_i\}}_{i \in I}\),
    and \(B' = {\{\phi_i\}}_{i \in I}\),
    where \(\phi_i(\vec{v}_j) = \delta_{ij}\).
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \(\phi_i(\sum_{j \in I} a_j \vec{v}_j) = a_i\); and
        \item Each \(\phi_i \in B'\) is uniquely defined by choice of \(B\).
    \end{enumerate}
\end{lemma}
\begin{proof}
    \(\phi_i\) are linear functionals, so we have
    \begin{equation*}
        \phi_i\pqty{\sum_{j \in I} a_j \vec{v}_j}
        = \sum_{j \in I} a_j \phi_i(\vec{v}_j)
        = \sum_{j \in I} a_j \delta_{ij}
        = a_i
    \end{equation*}

    Suppose \(\phi_i(\vec{v}_j) = \phi_{i'}(\vec{v}_j) = \delta_{ij}\).
    Since they agree on the basis \(B \subset V\),
    they must also agree on \(V\),
    so \(\phi_i = \phi_{i'}\).
\end{proof}

\begin{lemma}
    The dual basis \(B' \subset V'\) is linearly independent.
\end{lemma}
\begin{proof}
    Suppose \(B'\) not linearly independent.
    Then there exists some \(a_i\) such that \(\sum_{i \in I} a_i \phi_i = 0\).
    But we can evaluate at \(\vec{v}_j \in B\) to conclude that
    \(\sum_{i \in I} a_i \phi_i(\vec{v}_j) = a_j = 0\) for all \(j \in I\).
\end{proof}
\begin{proposition}
    If \(V\) is finite dimensional,
    then \(B' \subset V'\) is a basis.
\end{proposition}
\begin{proof}
    It suffices to prove that it is spanning.
    Suppose \(B = {\{\vec{v}_i\}}_{i=1}^n\),
    and \(\phi \in V'\) some functional.
    For any \(\vec{x} \in V\),
    \(\vec{x} = \sum_{i=1}^n a_i \vec{v}_i\),
    so
    \begin{equation*}
        \phi(\vec{x}) = \sum_{i=1}^n a_i \phi(\vec{v}_i)
        = \sum_{i=1}^n \phi(\vec{v}_i) \phi_i(\vec{x})
    \end{equation*}
    Hence \(\phi = \sum_{i=1}^n \phi(\vec{v}_i) \phi_i\).
\end{proof}
\begin{corollary}
    If \(V\) is finite dimensional,
    then \(\dim V = \dim V'\).
\end{corollary}
\begin{proof}
    The bases are the same size.
\end{proof}
\begin{remark}
    Note that `dual basis' is kind of a misnomer,
    since it does not form a basis in the case of infinite dimensions.
    Rather, the dual basis is the basis for the subspace of \(V'\)
    with finite support.
\end{remark}

\begin{proposition}
    \(\pqty{\bigoplus_i V_i}' \cong \prod_i V_i'\).
\end{proposition}
\begin{proof}
    Suppose \(\phi \in \pqty{\bigoplus_i V_i}'\).
    If we consider the usual restriction of \(\phi\) to each individual \(V_i\),
    and denote each of them \(\phi_i\),
    then the direct product of each of the \(\phi_i\)
    gives us a natural homomorphism
    from \(\pqty{\bigoplus_i V_i}' \to \prod_i V_i'\),
    \(\phi \mapsto (\phi_i)\).

    We shall explicitly construct the inverse as to show that it is an isomorphism.
    Consider \((\psi_i) \in \prod_i V_i'\).
    We can map this to some element \(\sum_i \psi_i\).
    Observe that although there might be infinitely many nonzero \(\psi_i\),
    when applied to \(\vec{x}_i \in V_i\), there are only finitely many nonzero \(\psi_i(\vec{x}_i)\) terms.

    We first check that these two homomorphisms are indeed homomorphisms,
    by checking linearity.
    The forward direction is almost by definition:
    \(a\phi + \chi\) restricts to \(a\phi_i + \chi_i\),
    so \(a\phi + \chi \mapsto (a\phi_i + \chi_i) = a(\phi_i) + (\chi_i)\).
    The reverse direction is similar:
    \(a(\psi_i) + (\omega_i) = (a\psi_i + \omega_i) \mapsto
    \sum_i a\psi_i + \omega_i = a\sum_i \psi_i + \sum_i \omega_i\).

    We then check that it is indeed an inverse.
    \begin{equation*}
        \phi\pqty{\sum_i \vec{x}_i} \overset{f}{\mapsto} (\phi_i(\vec{x}_i))
        = \sum_i \phi_i(\vec{x}_i) = \phi\pqty{\sum_i \vec{x}_i}
    \end{equation*}
\end{proof}

\begin{theorem}
    Suppose \(\vfunc{f}{V}{V''}{\vec{v}}{(\phi\mapsto\phi(\vec{v})) = \delta_{\vec{v}}}\),
    where \(\delta_{\vec{v}}\) is the evaluation map.
    This homomorphism is injective;
    furthermore, it is an isomorphism if and only if \(\dim_F(V) < \infty\).
\end{theorem}
\begin{proof}
    Suppose, by way of contradiction, that there is some \(\vec{v} \neq \vec{0}\)
    such that \(f(\vec{v}) = \delta_{\vec{v}} = 0\);
    this tells us there is some vector \(\vec{v} \in V\)
    such that any \(\phi \in V'\) evaluates it to \(\phi(\vec{v}) = 0\).
    But then, if we choose a basis for \(V\), such that it includes \(\vec{v}\),
    the corresponding dual basis would include some \(\phi_{\vec{v}}\)
    such that \(\phi_{\vec{v}}(\vec{v}) = 1\), which is a contradiction.

    Suppose \(V\) is a finite-dimensional vector space.
    Then it suffices to prove that \(f\) is a surjection.
    Let \({\{\vec{v}_i\}}_{i=1}^n \subset V\) be a basis,
    and \({\{\phi_i\}}_{i=1}^n \subset V'\) be its dual basis.
    Consider any \(\delta \in V''\).
    If we let \(a_i = \delta(\phi_i)\),
    and \(\vec{v} = \sum_{i=1}^n a_i\vec{v}_i\),
    then we see that
    \begin{equation*}
        f(\vec{v}) = \sum_{i=1}^n a_i f(\vec{v}_i)
        = \sum_{i=1}^n \delta(\phi_i) \delta_{\vec{v}_i}
        = \delta
    \end{equation*}
    Hence we have surjection.

    Now suppose \(V\) is an infinite-dimensional vector space.
    Then if \({\{\vec{v}_i\}}_{i \in I} \subset V\) is a basis,
    then \(V = \bigoplus_{i \in I} F\),
    and \(V' = \prod_{i \in I} F\).
    But we can immediately see that in infinite dimensions the dual basis does not form a basis,
    and hence there is no surjection from \(V \to V'\).
    Analogously there is no surjection from \(V' \to V''\).
    Hence there exists no surjection \(V \to V''\).
\end{proof}


\section{Tensor Product}

\subsection*{Bilinearity}

\begin{definition}
    Suppose \(U,V,W\) are vector spaces,
    and \(\func{f}{U \times V}{W}\) is a function.
    We say \(f\) is bilinear if it is linear in each variable.
    Similarly, if \(\func{f}{\prod_{i=1}^n V_i}{W}\) is a function,
    \(f\) is \(n\)-linear if it is linear in each variable.
\end{definition}
\begin{definition}
    We can generalize the inner product of vectors.
    Suppose \(U,V\) are vector spaces,
    with \({\{\vec{u}_i\}}_{i=1}^m,{\{\vec{v}_j\}}_{j=1}^n\) their respective bases.
    Then we can define a Gram matrix to be \(b_{ij} = \ip{\vec{u}_i}{\vec{v}_j}\),
    for some bilinear form \(\func{\ip{\cdot}{\cdot}}{U \times V}{F}\).
    Then the pairing becomes \(\ip{\vec{u}}{\vec{v}} = \vec{u}^T \vb{B} \vec{v}\),
    where \(\vb{B}\) is the Gram matrix.
\end{definition}
\begin{theorem}
    There is a bijection between the set of bilinear maps \(U \times V \to W\)
    and \(\Hom(U,\Hom(V,W))\).
\end{theorem}
\begin{proof}
    Consider a bilinear function \(\func{f}{U \times V}{W}\).
    If we fix any \(\vec{u} \in U\),
    we can define \(\func{f_{\vec{u}} = f(\vec{u},\cdot)}{V}{W}\).
    Then clearly \(f_{\vec{u}} \in \Hom(V,W)\),
    and \(\vec{u} \mapsto f_{\vec{u}}\) is in \(\Hom(U,\Hom(V,W))\).

    Now consider any arbitrary map \(\Hom(U,\Hom(V,W))\).
    Then for each \(\vec{u} \in U\) we have a corresponding \(f_{\vec{u}} \in \Hom(V,W)\),
    and this map is linear in \(U\).
    But \(f_{\vec{u}}\) is exactly the set of linear maps from \(V \to W\),
    so we have linearity in both \(U\) and \(V\) as desired.
\end{proof}
\begin{corollary}
    There is a bijection between the set of pairings \(\func{f}{U \times V}{F}\)
    and \(\Hom(U,V')\).
\end{corollary}
\begin{proof}
    \(\Hom(U,\Hom(V,F)) = \Hom(U,V')\).
\end{proof}
\begin{definition}
    A paring \(U \times V \to F\) is nondegenerate
    if the associated maps \(U \mapsto V'\) and \(V \mapsto U'\) are both embeddings.
\end{definition}

\begin{definition}
    Suppose \(T \in \Hom(U,V)\).
    We define the dual map to be \(T' \in \Hom(V',U')\),
    where we map \(\phi \mapsto \phi \circ T\).
\end{definition}
\begin{proposition}
    We have the following properties for dual maps:
    \begin{enumerate}[label={(\alph*)}, itemsep=0mm]
        \item \(T \mapsto T'\) is a linear map from \(\Hom(U,V) \to \Hom(V',U')\);
        \item \({(ST)}' = T'S'\); and
        \item if \(\vb{A}\) is the matrix of \(T\), then \(\vb{A}^T\) is the matrix of \(T'\).
    \end{enumerate}
\end{proposition}
\begin{proof}
    Suppose \(S,T \in \Hom(U,V)\).
    Then for any \(\phi \in V'\),
    \begin{equation*}
        (aS + T)'\phi = \phi \circ (aS + T) = a\phi \circ S + \phi \circ T
        = aS' + T'
    \end{equation*}
    This proves statement (a).

    Suppose \(T \in \Hom(U,V)\) and \(S \in \Hom(V,W)\).
    Then for any \(\phi \in W'\),
    \begin{equation*}
        {(ST)}'\phi = \phi \circ ST = (\phi \circ S) \circ T
        = T'(\phi \circ S) = T'S'\phi
    \end{equation*}
    This proves statement (b).

    Suppose \(T \in \Hom(U,V)\), and \(\vb{A}\) is its matrix representation.
    Let \(\phi \in V'\) be a linear functional,
    with a representation \(\phi_i\) as a horizontal covector.
    % and we have bases \({\{\vec{u}_i\}}_{i=1}^m\) and \({\{\vec{v}_j\}}_{j=1}^n\).
    % Let \(a_{ij}\) be the matrix elements of \(\vb{A}\),
    % and \(\vec{u} = \sum_{k=1}^m b_k\vec{u}_k\).
    % We have
    % \begin{equation*}
    %     T\vec{u} =  \sum_{i,j} a_{ij}b_j\vec{v}_i
    % \end{equation*}
    Then we have
    \begin{equation*}
        \pqty{\phi\vb{A}}^T
        = \vb{A}^T\phi^T
    \end{equation*}
    where the left multiplication is by \(\vb{A}^T\).
    This proves statement (c).
\end{proof}
\begin{remark}
    Although we have not proven all the corresponding properties,
    we can see intuitively that taking the dual is a contravariant functor.
    Functoriality of \(\Hom(\cdot,F)\) will be discussed in more generality
    in Section~\ref{sec:comm-modules} for modules over commutative rings.
\end{remark}
% \begin{proposition}
%     Suppose \(T \in \End(V,V)\) is arbitrary.
%     Then there exists a unique nondegenerate pairing \(\func{\ip{\cdot}{\cdot}}{V' \times V}{F}\)
%     such that \(\ip{\phi}{T\vec{v}} = \ip{T'\phi}{\vec{v}}\) holds
%     for all \(\vec{v} \in V\) and \(\phi \in V'\).
% \end{proposition}
% \begin{proof}
    
% \end{proof}

\subsection*{Tensor Product}

\begin{definition}[Universal Property of Tensor Product]
    Suppose \({\{V_i\}}_{i \in I}\) is a family of vector spaces.
    The tensor product of vector spaces \(\bigotimes_{i \in I} V_i\)
    is the universal construction for all \(I\)-linear maps, that is,
    \begin{enumerate}[label={(\roman*)}, itemsep=0mm]
        \item there exists a bilinear embedding \(\func{\iota}{\prod_{i \in I} V_i}{\bigotimes_{i \in I} V_i}\); and
        \item for any vector space \(X\),
            if \(\func{\phi}{\prod_{i \in I} V_i}{X}\) is a bilinear map,
            then there exists a unique \(\func{\bar{\phi}}{\bigotimes_{i \in I} V_i}{X}\)
            such that \(\phi = \bar{\phi}\circ\iota\).
    \end{enumerate}

    This can be represented by the following commutative diagram:
    \begin{center}
        \begin{tikzcd}
            \prod_{i \in I} V_i \arrow{r}{\phi} \arrow{d}{\iota} & X \\
            \bigotimes_{i \in I} V_i \arrow[dashrightarrow]{ru}[swap]{\exists! \bar{\phi}}
        \end{tikzcd}
    \end{center}
\end{definition}

\begin{theorem}[Uniqueness of Tensor Product]
    The tensor product is unique up to isomorphism.
\end{theorem}
\begin{proof}
    Suppose, by way of contradiction, that there exists another vector space \(W\)
    that fits that universal property.
    \begin{center}
        \begin{tikzcd}
            \prod_{i \in I} V_i \arrow{r}{\iota'} \arrow{d}{\iota} &
            W \arrow[rightharpoondown, shift right=0.25ex]{ld}%
                [xshift=.5ex, yshift=-.5ex, swap]{\bar{\phi}'} \\
            \bigotimes_{i \in I} V_i \arrow[rightharpoondown, shift right=0.25ex]{ru}%
                [xshift=-.5ex, yshift=.5ex, swap]{\bar{\phi}}
        \end{tikzcd}
    \end{center}
    A standard argument via diagram chase gives us
    \begin{align*}
        (\bar{\phi}'\circ\bar{\phi})\circ\iota = \iota &\implies \bar{\phi}'\circ\bar{\phi} = \id \\
        (\bar{\phi}\circ\bar{\phi}')\circ\iota' = \iota' &\implies \bar{\phi}\circ\bar{\phi}' = \id
    \end{align*}
    by uniqueness of \(\bar{\phi},\bar{\phi}'\).
    This gives us isomorphism.
\end{proof}

\begin{theorem}[Existence of Tensor Product]
    Suppose \({\{V_i\}}_{i \in I}\) is a family of vector spaces,
    Consider the vector space \(T\) of formal linear combinations of vectors
    \({\{{(\vec{v}_i)}_{i \in I} : \vec{v}_i \in V_i\}}\).
    We then construct the following equivalence classes,
    where the vectors below only differ in the \(i\)th index.
    \begin{equation*}
        (\hdots,\vec{u}_i+\vec{v}_i,\hdots) = (\hdots,\vec{u}_i,\hdots) + (\hdots,\vec{v}_i,\hdots) \qquad
        (\hdots,a\vec{v}_i,\hdots) = a(\hdots,\vec{v}_i,\hdots)
    \end{equation*}
    Then \(T/{\sim}\) is the tensor product,
    with the image of \({(\vec{v}_i)}_{i \in I}\) written as \(\bigotimes_{i \in I} \vec{v}_i\).
\end{theorem}
\begin{proof}
    We first remember that the equivalence class \(\sim\) indeed forms a vector space,
    since by construction,
    all linear combinations of elements will be in the equivalence class.
    Hence \(T/{\sim}\) is indeed a valid quotient vector space.

    We now show that \(T/{\sim}\) indeed fulfills our universal property.
\end{proof}


\section{Symmetry and Antisymmetry}


\section{Minimal Polynomial}


\section{Jordan Canonical Form}
